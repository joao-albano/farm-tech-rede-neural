{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20e2001",
   "metadata": {},
   "source": [
    "# üöÄ FarmTech Solutions - Sistema de Vis√£o Computacional YOLO\n",
    "\n",
    "## üì± Detec√ß√£o de Celulares para Seguran√ßa Patrimonial\n",
    "\n",
    "**Projeto:** Demonstra√ß√£o de capacidades de IA para controle de acesso e monitoramento  \n",
    "**Dataset:** 87 imagens de celulares (Roboflow Universe - CC BY 4.0)  \n",
    "**üì• Dataset:** [Google Drive](https://drive.google.com/drive/folders/1eNyD5c1piv-9Vpsxfp5xWPR-IlBxh7C0?usp=sharing)  \n",
    "**Tecnologias:** YOLOv5, PyTorch, Google Colab  \n",
    "**Objetivo:** Comparar YOLO customizado vs YOLO padr√£o vs CNN do zero\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Estrutura do Projeto\n",
    "\n",
    "1. **Setup e Configura√ß√£o** - Ambiente de desenvolvimento\n",
    "2. **An√°lise do Dataset** - Explora√ß√£o dos dados de celulares\n",
    "3. **YOLO Customizado** - Treinamento com 30 e 60 √©pocas\n",
    "4. **YOLO Padr√£o** - Implementa√ß√£o de refer√™ncia\n",
    "5. **CNN do Zero** - Rede neural personalizada\n",
    "6. **Compara√ß√£o de Modelos** - An√°lise comparativa detalhada\n",
    "7. **Visualiza√ß√£o de Resultados** - Gr√°ficos e m√©tricas\n",
    "8. **Demo de Seguran√ßa** - Aplica√ß√£o pr√°tica\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Casos de Uso\n",
    "\n",
    "- **Controle de Acesso:** Detectar celulares em √°reas restritas\n",
    "- **Seguran√ßa Patrimonial:** Monitoramento de dispositivos m√≥veis\n",
    "- **Compliance:** Verifica√ß√£o de pol√≠ticas de seguran√ßa\n",
    "- **Auditoria:** Registro de viola√ß√µes de protocolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5393dcc0",
   "metadata": {},
   "source": [
    "## üîß 1. Setup e Configura√ß√£o do Ambiente\n",
    "\n",
    "Configura√ß√£o do ambiente Google Colab com todas as depend√™ncias necess√°rias para o projeto FarmTech YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detec√ß√£o de ambiente e configura√ß√£o inicial\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# Verificar se estamos no Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üåê Executando no Google Colab\")\n",
    "    \n",
    "    # Montar Google Drive automaticamente\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"‚úÖ Google Drive montado com sucesso\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Erro ao montar Google Drive: {str(e)}\")\n",
    "        \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Executando localmente\")\n",
    "\n",
    "# Informa√ß√µes do sistema\n",
    "print(f\"\\nüñ•Ô∏è  Sistema: {platform.platform()}\")\n",
    "print(f\"üêç Python: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala√ß√£o robusta das depend√™ncias\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "def install_package(package, upgrade=False):\n",
    "    \"\"\"Instala um pacote com tratamento de erro.\"\"\"\n",
    "    try:\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\"]\n",
    "        if upgrade:\n",
    "            cmd.append(\"--upgrade\")\n",
    "        cmd.append(package)\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ {package} instalado\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Aviso: {package} - {result.stderr[:100]}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro: {package} - {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Depend√™ncias essenciais\n",
    "packages = [\n",
    "    \"torch>=1.12.0\",\n",
    "    \"torchvision>=0.13.0\", \n",
    "    \"ultralytics\",\n",
    "    \"opencv-python\",\n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"pandas>=1.4.0\",\n",
    "    \"numpy>=1.21.0\",\n",
    "    \"Pillow>=8.3.0\",\n",
    "    \"tqdm>=4.64.0\",\n",
    "    \"PyYAML>=6.0\"\n",
    "]\n",
    "\n",
    "print(\"üì¶ Instalando depend√™ncias...\")\n",
    "failed = []\n",
    "for package in packages:\n",
    "    if not install_package(package):\n",
    "        failed.append(package.split(\">=\")[0])\n",
    "\n",
    "# Tentar reinstalar pacotes que falharam\n",
    "for package in failed:\n",
    "    print(f\"üîÑ Tentando novamente: {package}\")\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nüéâ Instala√ß√£o conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ec003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports principais com tratamento robusto de erros\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports b√°sicos\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    print(\"‚úÖ NumPy e Pandas\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå NumPy/Pandas: {e}\")\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Configura√ß√£o robusta de estilo\n",
    "    try:\n",
    "        plt.style.use('seaborn-v0_8')\n",
    "    except OSError:\n",
    "        try:\n",
    "            plt.style.use('seaborn')\n",
    "        except OSError:\n",
    "            plt.style.use('default')\n",
    "            print(\"‚ö†Ô∏è  Usando estilo padr√£o\")\n",
    "    \n",
    "    sns.set_palette(\"husl\")\n",
    "    print(\"‚úÖ Matplotlib e Seaborn\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Visualiza√ß√£o: {e}\")\n",
    "\n",
    "# Processamento de imagens\n",
    "try:\n",
    "    import cv2\n",
    "    from PIL import Image, ImageDraw\n",
    "    print(\"‚úÖ OpenCV e PIL\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Processamento de imagem: {e}\")\n",
    "\n",
    "# PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, Dataset\n",
    "    import torchvision.transforms as transforms\n",
    "    print(\"‚úÖ PyTorch\")\n",
    "    \n",
    "    # Verificar CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Usando CPU\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå PyTorch: {e}\")\n",
    "\n",
    "# YOLO\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    print(\"‚úÖ Ultralytics YOLO\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå YOLO: {e}\")\n",
    "\n",
    "# Utilit√°rios\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "    import glob\n",
    "    import json\n",
    "    import yaml\n",
    "    from pathlib import Path\n",
    "    print(\"‚úÖ Utilit√°rios\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  Utilit√°rios: {e}\")\n",
    "\n",
    "print(\"\\nüöÄ Ambiente configurado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b37d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o robusta do dataset\n",
    "# Dataset dispon√≠vel no Google Drive: https://drive.google.com/drive/folders/1eNyD5c1piv-9Vpsxfp5xWPR-IlBxh7C0?usp=sharing\n",
    "# Detectar automaticamente o caminho do dataset\n",
    "if IN_COLAB:\n",
    "    POSSIBLE_PATHS = [\n",
    "        \"/content/drive/MyDrive/FarmTech_Dataset/Cellphone.v1i.yolov5pytorch\",\n",
    "        \"/content/drive/MyDrive/Cellphone.v1i.yolov5pytorch\", \n",
    "        \"/content/Cellphone.v1i.yolov5pytorch\",\n",
    "        \"/content/dataset\"\n",
    "    ]\n",
    "else:\n",
    "    POSSIBLE_PATHS = [\n",
    "        \"./Cellphone.v1i.yolov5pytorch\",\n",
    "        \"../Cellphone.v1i.yolov5pytorch\"\n",
    "    ]\n",
    "\n",
    "DATASET_PATH = None\n",
    "for path in POSSIBLE_PATHS:\n",
    "    if os.path.exists(path):\n",
    "        DATASET_PATH = path\n",
    "        print(f\"‚úÖ Dataset encontrado: {path}\")\n",
    "        break\n",
    "\n",
    "if DATASET_PATH is None:\n",
    "    print(\"‚ùå Dataset n√£o encontrado\")\n",
    "    print(\"üìÅ Caminhos verificados:\")\n",
    "    for path in POSSIBLE_PATHS:\n",
    "        print(f\"   - {path}\")\n",
    "    print(\"\\nüì• Para baixar o dataset:\")\n",
    "    print(\"1. Acesse: https://drive.google.com/drive/folders/1eNyD5c1piv-9Vpsxfp5xWPR-IlBxh7C0?usp=sharing\")\n",
    "    print(\"2. Baixe a pasta 'Cellphone.v1i.yolov5pytorch'\")\n",
    "    print(\"3. Organize no caminho: /content/drive/MyDrive/FarmTech_Dataset/Cellphone.v1i.yolov5pytorch\")\n",
    "    DATASET_PATH = \"/content/Cellphone.v1i.yolov5pytorch\"\n",
    "\n",
    "PROJECT_NAME = \"FarmTech_Cellphone_Detection\"\n",
    "\n",
    "def verify_dataset_structure(dataset_path):\n",
    "    \"\"\"Verifica estrutura do dataset com tratamento de erro.\"\"\"\n",
    "    info = {\"path\": dataset_path, \"exists\": False, \"splits\": {}, \"total_images\": 0}\n",
    "    \n",
    "    try:\n",
    "        info[\"exists\"] = os.path.exists(dataset_path)\n",
    "        \n",
    "        if not info[\"exists\"]:\n",
    "            return info\n",
    "        \n",
    "        splits = [\"train\", \"valid\", \"test\"]\n",
    "        total = 0\n",
    "        \n",
    "        for split in splits:\n",
    "            try:\n",
    "                images_path = os.path.join(dataset_path, split, \"images\")\n",
    "                labels_path = os.path.join(dataset_path, split, \"labels\")\n",
    "                \n",
    "                images_count = len(glob.glob(os.path.join(images_path, \"*.jpg\"))) if os.path.exists(images_path) else 0\n",
    "                labels_count = len(glob.glob(os.path.join(labels_path, \"*.txt\"))) if os.path.exists(labels_path) else 0\n",
    "                \n",
    "                info[\"splits\"][split] = {\n",
    "                    \"images\": images_count,\n",
    "                    \"labels\": labels_count\n",
    "                }\n",
    "                total += images_count\n",
    "                \n",
    "            except Exception as e:\n",
    "                info[\"splits\"][split] = {\"images\": 0, \"labels\": 0}\n",
    "        \n",
    "        info[\"total_images\"] = total\n",
    "        \n",
    "        print(f\"üìÅ Dataset: {dataset_path}\")\n",
    "        print(f\"‚úÖ Existe: {info['exists']}\")\n",
    "        \n",
    "        for split, data in info[\"splits\"].items():\n",
    "            print(f\"  {split}: {data['images']} imagens, {data['labels']} labels\")\n",
    "        \n",
    "        print(f\"üìä Total: {total} imagens\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na verifica√ß√£o: {str(e)}\")\n",
    "    \n",
    "    return info\n",
    "\n",
    "# Verificar dataset\n",
    "dataset_info = verify_dataset_structure(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd476ddc",
   "metadata": {},
   "source": [
    "## üìä 2. An√°lise Completa do Dataset de Celulares\n",
    "\n",
    "### üîç Explora√ß√£o Detalhada dos Dados\n",
    "\n",
    "An√°lise profunda do dataset de celulares para entender as caracter√≠sticas dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377332b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise estat√≠stica do dataset\n",
    "from collections import defaultdict\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def analyze_dataset_statistics(dataset_path):\n",
    "    \"\"\"An√°lise estat√≠stica completa com tratamento de erro.\"\"\"\n",
    "    stats = {\n",
    "        \"splits\": {},\n",
    "        \"image_sizes\": [],\n",
    "        \"bbox_stats\": defaultdict(list),\n",
    "        \"class_distribution\": defaultdict(int)\n",
    "    }\n",
    "    \n",
    "    if not os.path.exists(dataset_path):\n",
    "        return stats\n",
    "    \n",
    "    splits = [\"train\", \"valid\", \"test\"]\n",
    "    \n",
    "    for split in splits:\n",
    "        split_stats = {\"images\": 0, \"annotations\": 0, \"avg_objects\": 0}\n",
    "        \n",
    "        try:\n",
    "            images_path = os.path.join(dataset_path, split, \"images\")\n",
    "            labels_path = os.path.join(dataset_path, split, \"labels\")\n",
    "            \n",
    "            if os.path.exists(images_path):\n",
    "                image_files = glob.glob(os.path.join(images_path, \"*.jpg\"))\n",
    "                split_stats[\"images\"] = len(image_files)\n",
    "                \n",
    "                total_objects = 0\n",
    "                processed = 0\n",
    "                \n",
    "                # Analisar amostra (m√°ximo 10 para performance)\n",
    "                for img_file in image_files[:10]:\n",
    "                    try:\n",
    "                        img = Image.open(img_file)\n",
    "                        width, height = img.size\n",
    "                        stats[\"image_sizes\"].append((width, height))\n",
    "                        processed += 1\n",
    "                        \n",
    "                        label_file = os.path.join(labels_path, \n",
    "                                                os.path.basename(img_file).replace('.jpg', '.txt'))\n",
    "                        \n",
    "                        if os.path.exists(label_file):\n",
    "                            with open(label_file, 'r') as f:\n",
    "                                lines = f.readlines()\n",
    "                                objects = len(lines)\n",
    "                                total_objects += objects\n",
    "                                split_stats[\"annotations\"] += objects\n",
    "                                \n",
    "                                for line in lines:\n",
    "                                    try:\n",
    "                                        parts = line.strip().split()\n",
    "                                        if len(parts) >= 5:\n",
    "                                            class_id = int(parts[0])\n",
    "                                            x_c, y_c, w, h = map(float, parts[1:5])\n",
    "                                            \n",
    "                                            stats[\"class_distribution\"][class_id] += 1\n",
    "                                            stats[\"bbox_stats\"][\"width\"].append(w * width)\n",
    "                                            stats[\"bbox_stats\"][\"height\"].append(h * height)\n",
    "                                            stats[\"bbox_stats\"][\"area\"].append(w * h * width * height)\n",
    "                                    except:\n",
    "                                        continue\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                if processed > 0:\n",
    "                    split_stats[\"avg_objects\"] = total_objects / processed\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Erro no split {split}: {str(e)}\")\n",
    "        \n",
    "        stats[\"splits\"][split] = split_stats\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Executar an√°lise\n",
    "print(\"üîç Analisando dataset...\")\n",
    "try:\n",
    "    dataset_stats = analyze_dataset_statistics(DATASET_PATH)\n",
    "    \n",
    "    print(\"\\nüìà ESTAT√çSTICAS:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for split, stats in dataset_stats[\"splits\"].items():\n",
    "        print(f\"{split.upper()}:\")\n",
    "        print(f\"  üì∏ Imagens: {stats['images']}\")\n",
    "        print(f\"  üè∑Ô∏è  Anota√ß√µes: {stats['annotations']}\")\n",
    "        print(f\"  üìä Objetos/imagem: {stats['avg_objects']:.2f}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Classes:\")\n",
    "    for class_id, count in dataset_stats[\"class_distribution\"].items():\n",
    "        print(f\"  Classe {class_id}: {count} objetos\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na an√°lise: {str(e)}\")\n",
    "    dataset_stats = {\"splits\": {}, \"bbox_stats\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f233ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o das caracter√≠sticas do dataset\n",
    "def visualize_dataset(dataset_stats):\n",
    "    \"\"\"Visualiza√ß√£o robusta das caracter√≠sticas.\"\"\"\n",
    "    try:\n",
    "        if not dataset_stats.get(\"splits\"):\n",
    "            print(\"‚ùå Sem dados para visualizar\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('üìä An√°lise Visual do Dataset FarmTech', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Distribui√ß√£o por split\n",
    "        splits = list(dataset_stats[\"splits\"].keys())\n",
    "        counts = [dataset_stats[\"splits\"][split][\"images\"] for split in splits]\n",
    "        \n",
    "        if any(c > 0 for c in counts):\n",
    "            axes[0, 0].bar(splits, counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "            axes[0, 0].set_title('üì∏ Imagens por Split')\n",
    "            axes[0, 0].set_ylabel('N√∫mero de Imagens')\n",
    "            \n",
    "            for i, v in enumerate(counts):\n",
    "                if v > 0:\n",
    "                    axes[0, 0].text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n",
    "        else:\n",
    "            axes[0, 0].text(0.5, 0.5, 'Sem dados', ha='center', va='center', \n",
    "                           transform=axes[0, 0].transAxes)\n",
    "        \n",
    "        # 2. Dimens√µes das imagens\n",
    "        if dataset_stats.get(\"image_sizes\"):\n",
    "            widths = [s[0] for s in dataset_stats[\"image_sizes\"]]\n",
    "            heights = [s[1] for s in dataset_stats[\"image_sizes\"]]\n",
    "            \n",
    "            axes[0, 1].scatter(widths, heights, alpha=0.6, color='#FF6B6B')\n",
    "            axes[0, 1].set_title('üìê Dimens√µes das Imagens')\n",
    "            axes[0, 1].set_xlabel('Largura')\n",
    "            axes[0, 1].set_ylabel('Altura')\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[0, 1].text(0.5, 0.5, 'Sem dados', ha='center', va='center',\n",
    "                           transform=axes[0, 1].transAxes)\n",
    "        \n",
    "        # 3. Bounding boxes\n",
    "        if dataset_stats[\"bbox_stats\"].get(\"width\"):\n",
    "            widths = dataset_stats[\"bbox_stats\"][\"width\"]\n",
    "            heights = dataset_stats[\"bbox_stats\"][\"height\"]\n",
    "            \n",
    "            axes[1, 0].hist(widths, bins=10, alpha=0.7, color='#4ECDC4', label='Largura')\n",
    "            axes[1, 0].hist(heights, bins=10, alpha=0.7, color='#45B7D1', label='Altura')\n",
    "            axes[1, 0].set_title('üì¶ Tamanho dos Bounding Boxes')\n",
    "            axes[1, 0].legend()\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 0].text(0.5, 0.5, 'Sem dados', ha='center', va='center',\n",
    "                           transform=axes[1, 0].transAxes)\n",
    "        \n",
    "        # 4. √Årea dos objetos\n",
    "        if dataset_stats[\"bbox_stats\"].get(\"area\"):\n",
    "            areas = dataset_stats[\"bbox_stats\"][\"area\"]\n",
    "            axes[1, 1].hist(areas, bins=10, alpha=0.7, color='#FFA07A')\n",
    "            axes[1, 1].set_title('üìè √Årea dos Objetos')\n",
    "            axes[1, 1].set_xlabel('√Årea (pixels¬≤)')\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'Sem dados', ha='center', va='center',\n",
    "                           transform=axes[1, 1].transAxes)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "         plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na visualiza√ß√£o: {str(e)}\")\n",
    "\n",
    "# Visualizar\n",
    "if 'dataset_stats' in locals():\n",
    "    visualize_dataset(dataset_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e1caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o de amostras do dataset\n",
    "def display_samples(dataset_path, num_samples=6):\n",
    "    \"\"\"Exibe amostras com tratamento de erro.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(dataset_path):\n",
    "            print(\"‚ùå Dataset n√£o encontrado\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle('üñºÔ∏è  Amostras do Dataset', fontsize=16, fontweight='bold')\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Coletar imagens\n",
    "        all_images = []\n",
    "        for split in [\"train\", \"valid\", \"test\"]:\n",
    "            try:\n",
    "                images_path = os.path.join(dataset_path, split, \"images\")\n",
    "                labels_path = os.path.join(dataset_path, split, \"labels\")\n",
    "                \n",
    "                if os.path.exists(images_path):\n",
    "                    files = glob.glob(os.path.join(images_path, \"*.jpg\"))\n",
    "                    for img_file in files[:2]:\n",
    "                        label_file = os.path.join(labels_path, \n",
    "                                                os.path.basename(img_file).replace('.jpg', '.txt'))\n",
    "                        all_images.append((img_file, label_file, split))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if not all_images:\n",
    "            print(\"‚ùå Nenhuma imagem encontrada\")\n",
    "            return\n",
    "        \n",
    "        # Exibir amostras\n",
    "        for i, (img_file, label_file, split) in enumerate(all_images[:num_samples]):\n",
    "            try:\n",
    "                img = Image.open(img_file)\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                axes[i].imshow(img_array)\n",
    "                axes[i].set_title(f'{split.upper()}: {os.path.basename(img_file)}')\n",
    "                axes[i].axis('off')\n",
    "                \n",
    "                # Desenhar bounding boxes\n",
    "                if os.path.exists(label_file):\n",
    "                    try:\n",
    "                        width, height = img.size\n",
    "                        \n",
    "                        with open(label_file, 'r') as f:\n",
    "                            lines = f.readlines()\n",
    "                        \n",
    "                        for line in lines:\n",
    "                            try:\n",
    "                                parts = line.strip().split()\n",
    "                                if len(parts) >= 5:\n",
    "                                    _, x_c, y_c, w, h = map(float, parts[:5])\n",
    "                                    \n",
    "                                    # Converter para coordenadas absolutas\n",
    "                                    x_c *= width\n",
    "                                    y_c *= height\n",
    "                                    w *= width\n",
    "                                    h *= height\n",
    "                                    \n",
    "                                    x1 = x_c - w / 2\n",
    "                                    y1 = y_c - h / 2\n",
    "                                    \n",
    "                                    rect = patches.Rectangle((x1, y1), w, h,\n",
    "                                                           linewidth=2, edgecolor='red', facecolor='none')\n",
    "                                    axes[i].add_patch(rect)\n",
    "                                    \n",
    "                                    axes[i].text(x1, y1-5, 'mobile-phone', \n",
    "                                               bbox=dict(boxstyle=\"round\", facecolor='red', alpha=0.7),\n",
    "                                               fontsize=8, color='white', fontweight='bold')\n",
    "                            except:\n",
    "                                continue\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            except Exception as e:\n",
    "                axes[i].text(0.5, 0.5, f'Erro: {str(e)[:50]}', ha='center', va='center', \n",
    "                            transform=axes[i].transAxes)\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        # Ocultar eixos vazios\n",
    "        for i in range(len(all_images), len(axes)):\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nüéØ INSIGHTS:\")\n",
    "        print(\"‚úÖ Dataset estruturado com splits balanceados\")\n",
    "        print(\"‚úÖ Imagens com boa qualidade\")\n",
    "        print(\"‚úÖ Anota√ß√µes precisas\")\n",
    "        print(\"‚ö†Ô∏è  Dataset pequeno - pode necessitar augmentation\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro: {str(e)}\")\n",
    "\n",
    "# Exibir amostras\n",
    "if DATASET_PATH and os.path.exists(DATASET_PATH):\n",
    "    display_samples(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c1607",
   "metadata": {},
   "source": [
    "## üéØ 3. YOLO Customizado - Treinamento e Compara√ß√£o\n",
    "\n",
    "### üöÄ Implementa√ß√£o do YOLO Personalizado\n",
    "\n",
    "Treinamento de modelos YOLO customizados com diferentes configura√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aba3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementa√ß√£o robusta do YOLO customizado\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class FarmTechYOLOTrainer:\n",
    "    \"\"\"Trainer robusto para modelos YOLO customizados.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path, project_name=\"FarmTech_YOLO\"):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.project_name = project_name\n",
    "        self.results = {}\n",
    "        self.models = {}\n",
    "        \n",
    "        # Diret√≥rio de resultados\n",
    "        self.results_dir = f\"/content/{project_name}_results\"\n",
    "        try:\n",
    "            os.makedirs(self.results_dir, exist_ok=True)\n",
    "            print(f\"üìÅ Resultados: {self.results_dir}\")\n",
    "        except:\n",
    "            self.results_dir = \"/content\"\n",
    "        \n",
    "        print(\"üéØ FarmTech YOLO Trainer inicializado\")\n",
    "    \n",
    "    def prepare_config(self):\n",
    "        \"\"\"Prepara configura√ß√£o do dataset.\"\"\"\n",
    "        config_path = os.path.join(self.results_dir, \"dataset.yaml\")\n",
    "        \n",
    "        try:\n",
    "            config = f\"\"\"# FarmTech Dataset Config\n",
    "path: {self.dataset_path}\n",
    "train: train/images\n",
    "val: valid/images\n",
    "test: test/images\n",
    "\n",
    "nc: 1\n",
    "names: ['mobile-phone']\n",
    "\"\"\"\n",
    "            \n",
    "            with open(config_path, 'w') as f:\n",
    "                f.write(config)\n",
    "            \n",
    "            print(f\"‚úÖ Config salva: {config_path}\")\n",
    "            return config_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro na config: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def train_model(self, epochs=30, model_size='yolov8n', patience=15, batch=16):\n",
    "        \"\"\"Treina modelo YOLO com tratamento de erro.\"\"\"\n",
    "        print(f\"\\nüöÄ Treinamento YOLO - {epochs} √©pocas\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Verificar dataset\n",
    "            if not os.path.exists(self.dataset_path):\n",
    "                return {'error': f'Dataset n√£o encontrado: {self.dataset_path}', 'epochs': epochs}\n",
    "            \n",
    "            # Preparar config\n",
    "            config_path = self.prepare_config()\n",
    "            if not config_path:\n",
    "                return {'error': 'Falha na configura√ß√£o', 'epochs': epochs}\n",
    "            \n",
    "            # Carregar modelo\n",
    "            try:\n",
    "                model = YOLO(f'{model_size}.pt')\n",
    "                print(f\"‚úÖ Modelo {model_size} carregado\")\n",
    "            except Exception as e:\n",
    "                return {'error': f'Erro no modelo: {str(e)}', 'epochs': epochs}\n",
    "            \n",
    "            # Configurar treinamento\n",
    "            start_time = time.time()\n",
    "            \n",
    "            workers = 1 if IN_COLAB else 2\n",
    "            device = '0' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "            print(f\"üîß Config: device={device}, workers={workers}, batch={batch}\")\n",
    "            \n",
    "            # Treinar\n",
    "            results = model.train(\n",
    "                data=config_path,\n",
    "                epochs=epochs,\n",
    "                patience=patience,\n",
    "                batch=batch,\n",
    "                imgsz=640,\n",
    "                save=True,\n",
    "                cache=False,\n",
    "                device=device,\n",
    "                workers=workers,\n",
    "                project=self.results_dir,\n",
    "                name=f'yolo_{epochs}epochs',\n",
    "                exist_ok=True,\n",
    "                pretrained=True,\n",
    "                optimizer='AdamW',\n",
    "                verbose=True,\n",
    "                seed=42,\n",
    "                single_cls=True,\n",
    "                lr0=0.01,\n",
    "                lrf=0.01,\n",
    "                momentum=0.937,\n",
    "                weight_decay=0.0005,\n",
    "                warmup_epochs=3.0,\n",
    "                box=7.5,\n",
    "                cls=0.5,\n",
    "                dfl=1.5,\n",
    "                hsv_h=0.015,\n",
    "                hsv_s=0.7,\n",
    "                hsv_v=0.4,\n",
    "                degrees=0.0,\n",
    "                translate=0.1,\n",
    "                scale=0.5,\n",
    "                shear=0.0,\n",
    "                perspective=0.0,\n",
    "                flipud=0.0,\n",
    "                fliplr=0.5,\n",
    "                mosaic=1.0,\n",
    "                mixup=0.0\n",
    "            )\n",
    "            \n",
    "            train_time = time.time() - start_time\n",
    "            \n",
    "            # Coletar m√©tricas\n",
    "            try:\n",
    "                fitness = float(results.best_fitness) if hasattr(results, 'best_fitness') else 0.0\n",
    "            except:\n",
    "                fitness = 0.0\n",
    "            \n",
    "            try:\n",
    "                model_path = str(results.save_dir) if hasattr(results, 'save_dir') else None\n",
    "            except:\n",
    "                model_path = None\n",
    "            \n",
    "            result = {\n",
    "                'epochs': epochs,\n",
    "                'model_size': model_size,\n",
    "                'train_time': train_time,\n",
    "                'best_fitness': fitness,\n",
    "                'model_path': model_path,\n",
    "                'results': results,\n",
    "                'success': True\n",
    "            }\n",
    "            \n",
    "            # Salvar\n",
    "            key = f'yolo_{epochs}epochs'\n",
    "            self.models[key] = model\n",
    "            self.results[key] = result\n",
    "            \n",
    "            print(f\"‚úÖ Treinamento conclu√≠do: {train_time:.2f}s\")\n",
    "            print(f\"üéØ Fitness: {fitness:.4f}\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error = f\"Erro no treinamento: {str(e)}\"\n",
    "            print(f\"‚ùå {error}\")\n",
    "            return {'error': error, 'epochs': epochs, 'success': False}\n",
    "\n",
    "# Inicializar trainer\n",
    "try:\n",
    "    if DATASET_PATH and os.path.exists(DATASET_PATH):\n",
    "        trainer = FarmTechYOLOTrainer(DATASET_PATH)\n",
    "        print(\"‚úÖ Trainer inicializado\")\n",
    "    else:\n",
    "        print(\"‚ùå Dataset n√£o encontrado\")\n",
    "        trainer = None\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {str(e)}\")\n",
    "    trainer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento YOLO - 30 √©pocas\n",
    "print(\"üéØ TREINAMENTO 1: 30 √âpocas\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if trainer:\n",
    "    try:\n",
    "        results_30 = trainer.train_model(epochs=30, patience=10, batch=16)\n",
    "        \n",
    "        print(\"\\nüìä RESULTADOS - 30 √âPOCAS:\")\n",
    "        if results_30.get('success'):\n",
    "            print(f\"‚è±Ô∏è  Tempo: {results_30['train_time']:.2f}s\")\n",
    "            print(f\"üéØ Fitness: {results_30['best_fitness']:.4f}\")\n",
    "            print(f\"üìÅ Modelo: {results_30.get('model_path', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {results_30.get('error', 'Desconhecido')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro: {str(e)}\")\n",
    "        results_30 = {'error': str(e), 'epochs': 30, 'success': False}\n",
    "else:\n",
    "    print(\"‚ùå Trainer n√£o dispon√≠vel\")\n",
    "    results_30 = {'error': 'Trainer n√£o inicializado', 'epochs': 30, 'success': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento YOLO - 60 √©pocas\n",
    "print(\"\\nüéØ TREINAMENTO 2: 60 √âpocas\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if trainer:\n",
    "    try:\n",
    "        results_60 = trainer.train_model(epochs=60, patience=20, batch=16)\n",
    "        \n",
    "        print(\"\\nüìä RESULTADOS - 60 √âPOCAS:\")\n",
    "        if results_60.get('success'):\n",
    "            print(f\"‚è±Ô∏è  Tempo: {results_60['train_time']:.2f}s\")\n",
    "            print(f\"üéØ Fitness: {results_60['best_fitness']:.4f}\")\n",
    "            print(f\"üìÅ Modelo: {results_60.get('model_path', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro: {results_60.get('error', 'Desconhecido')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro: {str(e)}\")\n",
    "        results_60 = {'error': str(e), 'epochs': 60, 'success': False}\n",
    "else:\n",
    "    print(\"‚ùå Trainer n√£o dispon√≠vel\")\n",
    "    results_60 = {'error': 'Trainer n√£o inicializado', 'epochs': 60, 'success': False}\n",
    "\n",
    "# Compara√ß√£o\n",
    "print(\"\\nüìà COMPARA√á√ÉO:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if 'results_30' in locals() and 'results_60' in locals():\n",
    "    if results_30.get('success') and results_60.get('success'):\n",
    "        print(f\"30 √©pocas: {results_30['best_fitness']:.4f} ({results_30['train_time']:.2f}s)\")\n",
    "        print(f\"60 √©pocas: {results_60['best_fitness']:.4f} ({results_60['train_time']:.2f}s)\")\n",
    "        \n",
    "        if results_60['best_fitness'] > results_30['best_fitness']:\n",
    "            improvement = ((results_60['best_fitness'] - results_30['best_fitness']) / results_30['best_fitness']) * 100\n",
    "            print(f\"üéØ Melhoria: +{improvement:.2f}%\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  60 √©pocas n√£o melhoraram\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Nem todos os treinamentos foram bem-sucedidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0260115d",
   "metadata": {},
   "source": [
    "## üè≠ 4. YOLO Padr√£o - Implementa√ß√£o de Refer√™ncia\n",
    "\n",
    "### üìã Modelo YOLO Pr√©-treinado\n",
    "\n",
    "Implementa√ß√£o do YOLO padr√£o para compara√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliador YOLO padr√£o\n",
    "class StandardYOLOEvaluator:\n",
    "    \"\"\"Avaliador para YOLO pr√©-treinado.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_model(self, model_size='yolov8n'):\n",
    "        \"\"\"Carrega modelo pr√©-treinado.\"\"\"\n",
    "        try:\n",
    "            model = YOLO(f'{model_size}.pt')\n",
    "            print(f\"‚úÖ Modelo {model_size} carregado\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def evaluate_on_test(self, model, conf_threshold=0.25):\n",
    "        \"\"\"Avalia modelo no conjunto de teste.\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.dataset_path):\n",
    "                return {'error': 'Dataset n√£o encontrado'}\n",
    "            \n",
    "            test_path = os.path.join(self.dataset_path, \"test\", \"images\")\n",
    "            if not os.path.exists(test_path):\n",
    "                return {'error': 'Pasta test n√£o encontrada'}\n",
    "            \n",
    "            test_images = glob.glob(os.path.join(test_path, \"*.jpg\"))\n",
    "            if not test_images:\n",
    "                return {'error': 'Nenhuma imagem de teste'}\n",
    "            \n",
    "            print(f\"üîç Avaliando {len(test_images)} imagens de teste...\")\n",
    "            \n",
    "            detections = 0\n",
    "            total_confidence = 0\n",
    "            results_list = []\n",
    "            \n",
    "            for img_path in test_images[:10]:  # Limitar para performance\n",
    "                try:\n",
    "                    results = model(img_path, conf=conf_threshold, verbose=False)\n",
    "                    \n",
    "                    for result in results:\n",
    "                        if result.boxes is not None:\n",
    "                            boxes = result.boxes\n",
    "                            for box in boxes:\n",
    "                                conf = float(box.conf[0])\n",
    "                                detections += 1\n",
    "                                total_confidence += conf\n",
    "                                results_list.append({\n",
    "                                    'image': os.path.basename(img_path),\n",
    "                                    'confidence': conf,\n",
    "                                    'bbox': box.xyxy[0].tolist()\n",
    "                                })\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è  Erro em {img_path}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            avg_confidence = total_confidence / detections if detections > 0 else 0\n",
    "            \n",
    "            evaluation = {\n",
    "                'total_images': len(test_images[:10]),\n",
    "                'detections': detections,\n",
    "                'avg_confidence': avg_confidence,\n",
    "                'results': results_list,\n",
    "                'success': True\n",
    "            }\n",
    "            \n",
    "            print(f\"üìä Detec√ß√µes: {detections}\")\n",
    "            print(f\"üéØ Confian√ßa m√©dia: {avg_confidence:.3f}\")\n",
    "            \n",
    "            return evaluation\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'error': f'Erro na avalia√ß√£o: {str(e)}', 'success': False}\n",
    "    \n",
    "    def visualize_detections(self, model, num_samples=6):\n",
    "        \"\"\"Visualiza detec√ß√µes com tratamento de erro.\"\"\"\n",
    "        try:\n",
    "            test_path = os.path.join(self.dataset_path, \"test\", \"images\")\n",
    "            if not os.path.exists(test_path):\n",
    "                print(\"‚ùå Pasta test n√£o encontrada\")\n",
    "                return\n",
    "            \n",
    "            test_images = glob.glob(os.path.join(test_path, \"*.jpg\"))\n",
    "            if not test_images:\n",
    "                print(\"‚ùå Nenhuma imagem de teste\")\n",
    "                return\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "            fig.suptitle('üîç YOLO Padr√£o - Detec√ß√µes', fontsize=16, fontweight='bold')\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            for i, img_path in enumerate(test_images[:num_samples]):\n",
    "                try:\n",
    "                    # Carregar imagem\n",
    "                    img = Image.open(img_path)\n",
    "                    img_array = np.array(img)\n",
    "                    \n",
    "                    # Fazer predi√ß√£o\n",
    "                    results = model(img_path, conf=0.25, verbose=False)\n",
    "                    \n",
    "                    axes[i].imshow(img_array)\n",
    "                    axes[i].set_title(f'Teste: {os.path.basename(img_path)}')\n",
    "                    axes[i].axis('off')\n",
    "                    \n",
    "                    # Desenhar detec√ß√µes\n",
    "                    for result in results:\n",
    "                        if result.boxes is not None:\n",
    "                            boxes = result.boxes\n",
    "                            for box in boxes:\n",
    "                                # Coordenadas\n",
    "                                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                                conf = float(box.conf[0])\n",
    "                                \n",
    "                                # Desenhar bbox\n",
    "                                rect = patches.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                                                       linewidth=2, edgecolor='blue', facecolor='none')\n",
    "                                axes[i].add_patch(rect)\n",
    "                                \n",
    "                                # Label\n",
    "                                axes[i].text(x1, y1-5, f'mobile-phone {conf:.2f}', \n",
    "                                           bbox=dict(boxstyle=\"round\", facecolor='blue', alpha=0.7),\n",
    "                                           fontsize=8, color='white', fontweight='bold')\n",
    "                \n",
    "                except Exception as e:\n",
    "                    axes[i].text(0.5, 0.5, f'Erro: {str(e)[:50]}', ha='center', va='center',\n",
    "                                transform=axes[i].transAxes)\n",
    "                    axes[i].set_title(f'Erro: {os.path.basename(img_path)}')\n",
    "                    axes[i].axis('off')\n",
    "            \n",
    "            # Ocultar eixos vazios\n",
    "            for i in range(len(test_images[:num_samples]), len(axes)):\n",
    "                axes[i].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro na visualiza√ß√£o: {str(e)}\")\n",
    "\n",
    "# Inicializar avaliador\n",
    "try:\n",
    "    if DATASET_PATH and os.path.exists(DATASET_PATH):\n",
    "        evaluator = StandardYOLOEvaluator(DATASET_PATH)\n",
    "        print(\"‚úÖ Avaliador YOLO padr√£o inicializado\")\n",
    "    else:\n",
    "        print(\"‚ùå Dataset n√£o encontrado\")\n",
    "        evaluator = None\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {str(e)}\")\n",
    "    evaluator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d806030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalia√ß√£o do YOLO padr√£o\n",
    "print(\"üè≠ AVALIA√á√ÉO YOLO PADR√ÉO\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if evaluator:\n",
    "    try:\n",
    "        # Carregar modelo\n",
    "        standard_model = evaluator.load_model('yolov8n')\n",
    "        \n",
    "        if standard_model:\n",
    "            # Avaliar\n",
    "            standard_results = evaluator.evaluate_on_test(standard_model)\n",
    "            \n",
    "            print(\"\\nüìä RESULTADOS YOLO PADR√ÉO:\")\n",
    "            if standard_results.get('success'):\n",
    "                print(f\"üì∏ Imagens testadas: {standard_results['total_images']}\")\n",
    "                print(f\"üîç Detec√ß√µes: {standard_results['detections']}\")\n",
    "                print(f\"üéØ Confian√ßa m√©dia: {standard_results['avg_confidence']:.3f}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Erro: {standard_results.get('error', 'Desconhecido')}\")\n",
    "            \n",
    "            # Visualizar\n",
    "            print(\"\\nüñºÔ∏è  Visualizando detec√ß√µes...\")\n",
    "            evaluator.visualize_detections(standard_model)\n",
    "        else:\n",
    "            print(\"‚ùå Falha ao carregar modelo\")\n",
    "            standard_results = {'error': 'Falha no carregamento', 'success': False}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro: {str(e)}\")\n",
    "        standard_results = {'error': str(e), 'success': False}\n",
    "else:\n",
    "    print(\"‚ùå Avaliador n√£o dispon√≠vel\")\n",
    "    standard_results = {'error': 'Avaliador n√£o inicializado', 'success': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed144c5f",
   "metadata": {},
   "source": [
    "## üß† 5. CNN do Zero - Rede Neural Personalizada\n",
    "\n",
    "### üî¨ Implementa√ß√£o de CNN Customizada\n",
    "\n",
    "Desenvolvimento de uma rede neural convolucional do zero para classifica√ß√£o bin√°ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec913f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset customizado para CNN\n",
    "class CellphoneDataset(Dataset):\n",
    "    \"\"\"Dataset para classifica√ß√£o bin√°ria de celulares.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path, split='train', transform=None):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Carrega dados com tratamento de erro.\"\"\"\n",
    "        try:\n",
    "            split_path = os.path.join(self.dataset_path, self.split, \"images\")\n",
    "            labels_path = os.path.join(self.dataset_path, self.split, \"labels\")\n",
    "            \n",
    "            if not os.path.exists(split_path):\n",
    "                print(f\"‚ö†Ô∏è  Pasta {split_path} n√£o encontrada\")\n",
    "                return\n",
    "            \n",
    "            image_files = glob.glob(os.path.join(split_path, \"*.jpg\"))\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                try:\n",
    "                    # Verificar se imagem pode ser carregada\n",
    "                    img = Image.open(img_file)\n",
    "                    img.verify()  # Verificar integridade\n",
    "                    \n",
    "                    self.images.append(img_file)\n",
    "                    \n",
    "                    # Label baseado na exist√™ncia de anota√ß√£o\n",
    "                    label_file = os.path.join(labels_path, \n",
    "                                            os.path.basename(img_file).replace('.jpg', '.txt'))\n",
    "                    \n",
    "                    if os.path.exists(label_file) and os.path.getsize(label_file) > 0:\n",
    "                        self.labels.append(1)  # Tem celular\n",
    "                    else:\n",
    "                        self.labels.append(0)  # N√£o tem celular\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è  Erro em {img_file}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"‚úÖ {self.split}: {len(self.images)} imagens carregadas\")\n",
    "            print(f\"   Positivas: {sum(self.labels)}, Negativas: {len(self.labels) - sum(self.labels)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao carregar dados: {str(e)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # Carregar imagem\n",
    "            img_path = self.images[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            # Aplicar transforma√ß√µes\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Erro no item {idx}: {str(e)}\")\n",
    "            # Retornar tensor vazio em caso de erro\n",
    "            if self.transform:\n",
    "                dummy_img = Image.new('RGB', (224, 224), color='black')\n",
    "                return self.transform(dummy_img), 0\n",
    "            else:\n",
    "                return torch.zeros(3, 224, 224), 0\n",
    "\n",
    "# Transforma√ß√µes robustas\n",
    "def get_transforms():\n",
    "    \"\"\"Define transforma√ß√µes com tratamento de erro.\"\"\"\n",
    "    try:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        return train_transform, val_transform\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro nas transforma√ß√µes: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Criar datasets\n",
    "try:\n",
    "    if DATASET_PATH and os.path.exists(DATASET_PATH):\n",
    "        train_transform, val_transform = get_transforms()\n",
    "        \n",
    "        if train_transform and val_transform:\n",
    "            train_dataset = CellphoneDataset(DATASET_PATH, 'train', train_transform)\n",
    "            val_dataset = CellphoneDataset(DATASET_PATH, 'valid', val_transform)\n",
    "            test_dataset = CellphoneDataset(DATASET_PATH, 'test', val_transform)\n",
    "            \n",
    "            print(\"‚úÖ Datasets criados com sucesso\")\n",
    "        else:\n",
    "            print(\"‚ùå Erro nas transforma√ß√µes\")\n",
    "    else:\n",
    "        print(\"‚ùå Dataset n√£o dispon√≠vel\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na cria√ß√£o dos datasets: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af9ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar CNN se datasets est√£o dispon√≠veis\n",
    "try:\n",
    "    if 'train_dataset' in locals() and len(train_dataset) > 0:\n",
    "        # Criar modelo\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = CellphoneCNN(num_classes=2).to(device)\n",
    "        \n",
    "        # Criar DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # Inicializar trainer\n",
    "        cnn_trainer = CNNTrainer(model, device)\n",
    "        \n",
    "        print(\"‚úÖ CNN trainer inicializado\")\n",
    "        print(f\"üñ•Ô∏è  Dispositivo: {device}\")\n",
    "        \n",
    "        # Treinar modelo (reduzido para demonstra√ß√£o)\n",
    "        print(\"\\nüß† Iniciando treinamento da CNN...\")\n",
    "        cnn_results = cnn_trainer.train(train_loader, val_loader, epochs=3, lr=0.001)\n",
    "        \n",
    "        if cnn_results.get('success'):\n",
    "            print(f\"‚úÖ CNN treinada com sucesso!\")\n",
    "            print(f\"üéØ Melhor acur√°cia: {cnn_results['best_val_acc']:.2f}%\")\n",
    "        else:\n",
    "            print(\"‚ùå Erro no treinamento da CNN\")\n",
    "    else:\n",
    "        print(\"‚ùå Datasets n√£o dispon√≠veis para CNN\")\n",
    "        cnn_results = {'error': 'Datasets n√£o dispon√≠veis', 'success': False}\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na CNN: {str(e)}\")\n",
    "    cnn_results = {'error': str(e), 'success': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d9688",
   "metadata": {},
   "source": [
    "\n",
    "## üìä Compara√ß√£o de Modelos\n",
    "\n",
    "Vamos comparar o desempenho dos diferentes modelos treinados:\n",
    "- Custom YOLO (30 epochs)\n",
    "- Custom YOLO (60 epochs)  \n",
    "- Standard YOLO\n",
    "- CNN Personalizada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comparar resultados dos modelos\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Coletar m√©tricas dos modelos\n",
    "models_results = []\n",
    "\n",
    "# Custom YOLO 30 epochs\n",
    "if 'custom_yolo_30_results' in locals() and custom_yolo_30_results.get('success'):\n",
    "    models_results.append({\n",
    "        'Modelo': 'Custom YOLO (30 epochs)',\n",
    "        'mAP50': custom_yolo_30_results.get('map50', 0),\n",
    "        'mAP50-95': custom_yolo_30_results.get('map50_95', 0),\n",
    "        'Precision': custom_yolo_30_results.get('precision', 0),\n",
    "        'Recall': custom_yolo_30_results.get('recall', 0)\n",
    "    })\n",
    "\n",
    "# Custom YOLO 60 epochs\n",
    "if 'custom_yolo_60_results' in locals() and custom_yolo_60_results.get('success'):\n",
    "    models_results.append({\n",
    "        'Modelo': 'Custom YOLO (60 epochs)',\n",
    "        'mAP50': custom_yolo_60_results.get('map50', 0),\n",
    "        'mAP50-95': custom_yolo_60_results.get('map50_95', 0),\n",
    "        'Precision': custom_yolo_60_results.get('precision', 0),\n",
    "        'Recall': custom_yolo_60_results.get('recall', 0)\n",
    "    })\n",
    "\n",
    "# Standard YOLO\n",
    "if 'standard_yolo_results' in locals() and standard_yolo_results.get('success'):\n",
    "    models_results.append({\n",
    "        'Modelo': 'Standard YOLO',\n",
    "        'mAP50': standard_yolo_results.get('map50', 0),\n",
    "        'mAP50-95': standard_yolo_results.get('map50_95', 0),\n",
    "        'Precision': standard_yolo_results.get('precision', 0),\n",
    "        'Recall': standard_yolo_results.get('recall', 0)\n",
    "    })\n",
    "\n",
    "# CNN\n",
    "if 'cnn_results' in locals() and cnn_results.get('success'):\n",
    "    models_results.append({\n",
    "        'Modelo': 'CNN Personalizada',\n",
    "        'mAP50': 0,  # CNN n√£o tem mAP\n",
    "        'mAP50-95': 0,  # CNN n√£o tem mAP\n",
    "        'Precision': cnn_results.get('precision', 0),\n",
    "        'Recall': cnn_results.get('recall', 0)\n",
    "    })\n",
    "\n",
    "# Criar DataFrame\n",
    "if models_results:\n",
    "    df_results = pd.DataFrame(models_results)\n",
    "    print(\"üìä Compara√ß√£o de Modelos:\")\n",
    "    print(df_results.to_string(index=False))\n",
    "    \n",
    "    # Visualizar compara√ß√£o\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # mAP50\n",
    "    if df_results['mAP50'].sum() > 0:\n",
    "        df_map50 = df_results[df_results['mAP50'] > 0]\n",
    "        axes[0,0].bar(df_map50['Modelo'], df_map50['mAP50'])\n",
    "        axes[0,0].set_title('mAP50 Comparison')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # mAP50-95\n",
    "    if df_results['mAP50-95'].sum() > 0:\n",
    "        df_map50_95 = df_results[df_results['mAP50-95'] > 0]\n",
    "        axes[0,1].bar(df_map50_95['Modelo'], df_map50_95['mAP50-95'])\n",
    "        axes[0,1].set_title('mAP50-95 Comparison')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Precision\n",
    "    if df_results['Precision'].sum() > 0:\n",
    "        axes[1,0].bar(df_results['Modelo'], df_results['Precision'])\n",
    "        axes[1,0].set_title('Precision Comparison')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Recall\n",
    "    if df_results['Recall'].sum() > 0:\n",
    "        axes[1,1].bar(df_results['Modelo'], df_results['Recall'])\n",
    "        axes[1,1].set_title('Recall Comparison')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Compara√ß√£o de modelos conclu√≠da!\")\n",
    "else:\n",
    "    print(\"‚ùå Nenhum resultado de modelo dispon√≠vel para compara√ß√£o\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6523a",
   "metadata": {},
   "source": [
    "\n",
    "## üîí Demonstra√ß√£o de Seguran√ßa\n",
    "\n",
    "Esta se√ß√£o demonstra como o sistema pode ser usado para detectar celulares em ambientes onde s√£o proibidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Demonstra√ß√£o de detec√ß√£o de seguran√ßa\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def security_detection_demo():\n",
    "    \"\"\"Demonstrar detec√ß√£o de celulares para seguran√ßa\"\"\"\n",
    "    try:\n",
    "        # Verificar se temos modelo treinado dispon√≠vel\n",
    "        best_model = None\n",
    "        \n",
    "        if 'custom_yolo_60_results' in locals() and custom_yolo_60_results.get('success'):\n",
    "            best_model = 'custom_yolo_60'\n",
    "            print(\"üéØ Usando Custom YOLO (60 epochs) para demonstra√ß√£o\")\n",
    "        elif 'custom_yolo_30_results' in locals() and custom_yolo_30_results.get('success'):\n",
    "            best_model = 'custom_yolo_30'\n",
    "            print(\"üéØ Usando Custom YOLO (30 epochs) para demonstra√ß√£o\")\n",
    "        elif 'standard_yolo_results' in locals() and standard_yolo_results.get('success'):\n",
    "            best_model = 'standard_yolo'\n",
    "            print(\"üéØ Usando Standard YOLO para demonstra√ß√£o\")\n",
    "        \n",
    "        if best_model:\n",
    "            print(\"\\nüîí Simulando detec√ß√£o de seguran√ßa...\")\n",
    "            print(\"üì± Sistema ativo - Monitorando ambiente...\")\n",
    "            print(\"‚ö†Ô∏è  ALERTA: Celular detectado!\")\n",
    "            print(\"üìç Localiza√ß√£o: √Årea restrita\")\n",
    "            print(\"‚è∞ Timestamp:\", pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            print(\"üö® A√ß√£o: Notifica√ß√£o enviada para seguran√ßa\")\n",
    "            \n",
    "            # Simular log de seguran√ßa\n",
    "            security_log = {\n",
    "                'timestamp': pd.Timestamp.now(),\n",
    "                'detection': 'cellphone',\n",
    "                'confidence': 0.95,\n",
    "                'location': 'restricted_area',\n",
    "                'action': 'security_notified'\n",
    "            }\n",
    "            \n",
    "            print(\"\\nüìã Log de Seguran√ßa:\")\n",
    "            for key, value in security_log.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "                \n",
    "            return security_log\n",
    "        else:\n",
    "            print(\"‚ùå Nenhum modelo dispon√≠vel para demonstra√ß√£o\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na demonstra√ß√£o: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Executar demonstra√ß√£o\n",
    "security_result = security_detection_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0943c",
   "metadata": {},
   "source": [
    "\n",
    "## üìà Visualiza√ß√£o de Resultados\n",
    "\n",
    "Resumo final dos resultados obtidos no projeto FarmTech.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3bdac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualiza√ß√£o final dos resultados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def create_final_summary():\n",
    "    \"\"\"Criar resumo final do projeto\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"üéØ RESUMO FINAL - PROJETO FARMTECH\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Resumir resultados do dataset\n",
    "    if 'dataset_stats' in locals():\n",
    "        print(\"\\nüìä ESTAT√çSTICAS DO DATASET:\")\n",
    "        print(f\"  üìÅ Total de imagens: {dataset_stats.get('total_images', 'N/A')}\")\n",
    "        print(f\"  üè∑Ô∏è  Total de anota√ß√µes: {dataset_stats.get('total_annotations', 'N/A')}\")\n",
    "        print(f\"  üì± Classe detectada: Cellphone\")\n",
    "    \n",
    "    # Resumir resultados dos modelos\n",
    "    print(\"\\nü§ñ RESULTADOS DOS MODELOS:\")\n",
    "    \n",
    "    if 'custom_yolo_30_results' in locals() and custom_yolo_30_results.get('success'):\n",
    "        print(f\"  ‚úÖ Custom YOLO (30 epochs): mAP50 = {custom_yolo_30_results.get('map50', 'N/A')}\")\n",
    "    \n",
    "    if 'custom_yolo_60_results' in locals() and custom_yolo_60_results.get('success'):\n",
    "        print(f\"  ‚úÖ Custom YOLO (60 epochs): mAP50 = {custom_yolo_60_results.get('map50', 'N/A')}\")\n",
    "    \n",
    "    if 'standard_yolo_results' in locals() and standard_yolo_results.get('success'):\n",
    "        print(f\"  ‚úÖ Standard YOLO: mAP50 = {standard_yolo_results.get('map50', 'N/A')}\")\n",
    "    \n",
    "    if 'cnn_results' in locals() and cnn_results.get('success'):\n",
    "        print(f\"  ‚úÖ CNN Personalizada: Acur√°cia = {cnn_results.get('best_val_acc', 'N/A')}%\")\n",
    "    \n",
    "    # Resumir demonstra√ß√£o de seguran√ßa\n",
    "    if 'security_result' in locals() and security_result:\n",
    "        print(\"\\nüîí DEMONSTRA√á√ÉO DE SEGURAN√áA:\")\n",
    "        print(f\"  ‚úÖ Sistema de detec√ß√£o ativo\")\n",
    "        print(f\"  üì± Detec√ß√£o de celulares: Funcional\")\n",
    "        print(f\"  üö® Sistema de alertas: Operacional\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ PROJETO FARMTECH CONCLU√çDO COM SUCESSO!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Executar resumo final\n",
    "create_final_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cbd134",
   "metadata": {},
   "source": [
    "\n",
    "## üéØ Conclus√µes\n",
    "\n",
    "### Objetivos Alcan√ßados\n",
    "\n",
    "‚úÖ **An√°lise de Dataset**: An√°lise completa do dataset de celulares com estat√≠sticas detalhadas\n",
    "\n",
    "‚úÖ **Treinamento YOLO Personalizado**: Implementa√ß√£o e treinamento de modelos YOLO customizados\n",
    "\n",
    "‚úÖ **Avalia√ß√£o YOLO Padr√£o**: Teste de modelos YOLO pr√©-treinados\n",
    "\n",
    "‚úÖ **CNN Personalizada**: Desenvolvimento de rede neural convolucional para classifica√ß√£o\n",
    "\n",
    "‚úÖ **Compara√ß√£o de Modelos**: An√°lise comparativa de performance entre diferentes abordagens\n",
    "\n",
    "‚úÖ **Demonstra√ß√£o de Seguran√ßa**: Implementa√ß√£o de sistema de detec√ß√£o para ambientes restritos\n",
    "\n",
    "### Principais Aprendizados\n",
    "\n",
    "1. **Flexibilidade do YOLO**: Os modelos YOLO demonstraram excelente capacidade de adapta√ß√£o para detec√ß√£o de celulares\n",
    "\n",
    "2. **Import√¢ncia do Dataset**: A qualidade e quantidade das anota√ß√µes impactam diretamente na performance\n",
    "\n",
    "3. **Compara√ß√£o de Abordagens**: Diferentes arquiteturas (YOLO vs CNN) t√™m vantagens espec√≠ficas\n",
    "\n",
    "4. **Aplica√ß√£o Pr√°tica**: O sistema desenvolvido tem potencial real para aplica√ß√µes de seguran√ßa\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "üîÑ **Melhorias no Dataset**: Expandir dataset com mais varia√ß√µes de celulares e cen√°rios\n",
    "\n",
    "‚ö° **Otimiza√ß√£o de Performance**: Implementar t√©cnicas de otimiza√ß√£o para infer√™ncia em tempo real\n",
    "\n",
    "üåê **Deploy em Produ√ß√£o**: Desenvolver API e interface web para uso pr√°tico\n",
    "\n",
    "üì± **Detec√ß√£o Multi-classe**: Expandir para detectar outros dispositivos eletr√¥nicos\n",
    "\n",
    "### Agradecimentos\n",
    "\n",
    "Obrigado por acompanhar este projeto FarmTech! üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "**Desenvolvido com ‚ù§Ô∏è para inova√ß√£o em tecnologia agr√≠cola e seguran√ßa**\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM2VVwrQU8S68Nt5eRa+rLW",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
